{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "#Import utility functions\n",
    "utilsPath = os.path.join(Path(os.getcwd()).parent.absolute(),'utils')\n",
    "if utilsPath not in sys.path:\n",
    "    sys.path.append(utilsPath)\n",
    "\n",
    "from modelFunctions import iou_coef, DiceLoss, weighted_categorical_crossentropy, prepUnetModel, compileUnetModel\n",
    "from getTiles import image_gen\n",
    "from getTiles import read_image\n",
    "\n",
    "#Import other modules\n",
    "import random\n",
    "import glob\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import rasterio\n",
    "\n",
    "from typing import Callable, Union\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, multilabel_confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from rasterio.plot import show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training tiles:  1248  Num validation tiles:  511\n",
      "First 5 training tiles:  [[103, 2001], [103, 2002], [103, 2003], [103, 2004], [103, 2005]]  First 5 validation tiles:  [[107, 2001], [107, 2002], [107, 2003], [107, 2004], [107, 2006]]\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "\n",
    "#Define seed\n",
    "seed = 30\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "\n",
    "#Define file path for label and bands\n",
    "trainingFolderPath = '../inputs/trainingPlots'\n",
    "validationFolderPath = '../inputs/validationPlots'\n",
    "bandFilePath = '../inputs/landsatTilesPostYear'\n",
    "labelFileFormat = 'plot_{}_{}.tif'\n",
    "labelFileFormat = 'Landsat7_{}_{}.tif'\n",
    "\n",
    "\n",
    "#Get list of [[plodID, treeCoverLossYear]] for training set and validation set\n",
    "trainingFileNames = glob.glob(os.path.join(trainingFolderPath,'*.tif'))\n",
    "trainingFileNames.sort()\n",
    "trainingPlots = [[int(x.split('_')[1]),int(x.split('_')[2].split('.')[0])] for x in trainingFileNames]\n",
    "\n",
    "validationFileNames = glob.glob(os.path.join(validationFolderPath,'*.tif'))\n",
    "validationFileNames.sort()\n",
    "validationPlots = [[int(x.split('_')[1]),int(x.split('_')[2].split('.')[0])] for x in validationFileNames]\n",
    "\n",
    "print('Num training tiles: ',len(trainingPlots), ' Num validation tiles: ',len(validationPlots))\n",
    "print('First 5 training tiles: ',trainingPlots[:5], ' First 5 validation tiles: ',validationPlots[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "n_classes=8\n",
    "n_features = 4\n",
    "image_size = 64\n",
    "batch_size=64\n",
    "bands = 'all'  #Format for listing bands: (1,5,6,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 09:58:48.886510: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Model name to save\n",
    "modelName = 'unet'\n",
    "runNum = 0\n",
    "\n",
    "\n",
    "#Define if we want to reinialize a new model\n",
    "newModel = True\n",
    "\n",
    "\n",
    "# Define weights for classes!\n",
    "classnames = ['No Loss','Hard commodities', 'Forest products', 'Other disturbances',\n",
    "                'Soft commodities', 'Settlements/infrastructure', 'Fires','Hansen Mistake']\n",
    "class_weights = np.array([1, 10, 10, 30,\n",
    "                          30, 30, 30,30]).astype(float)\n",
    "\n",
    "\n",
    "#Create new model\n",
    "if newModel==True:\n",
    "    model = compileUnetModel(n_classes, image_size, n_features, class_weights, learning_rate=0.001, w_decay=0.0005)\n",
    "\n",
    "# #Load model\n",
    "else:\n",
    "    model = keras.models.load_model('models/{}'.format(modelName+str(runNum)), custom_objects = {\"loss\":weighted_categorical_crossentropy(class_weights),\"iou_coef\": iou_coef, \"weighted_categorical_crossentropy\": weighted_categorical_crossentropy(class_weights)})\n",
    "\n",
    "##print to see model structure\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ls/m3fnvjqj1qs_hsp9k3s_q1h00000gp/T/ipykernel_57247/2906447310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#Fit the model!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m results = model.fit(train_sequence_generator, \n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_sequence_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#load seed\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "\n",
    "\n",
    "#Scheduler for decreating learning rate as epochs go on\n",
    "epochCutoff = 5\n",
    "def scheduler(epoch):\n",
    "    if epoch < epochCutoff:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.001 * tf.math.exp(0.1 * (epochCutoff - epoch))\n",
    "\n",
    "#Callbacks for training\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-{}-1.h5'.format(modelName), verbose=1, save_best_only=True)\n",
    "log_dir = 'reports/tensorboard/{}/'.format(modelName) + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch'\n",
    ")\n",
    "\n",
    "#Define generator for training and validation data\n",
    "train_sequence_generator = image_gen(trainingPlots,trainingFolderPath,bandFilePath,\n",
    "        n_classes,\n",
    "        n_features,\n",
    "        batch_size,\n",
    "        rotation_range=90,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,bands=bands)\n",
    "\n",
    "\n",
    "validation_sequence_generator = image_gen(validationPlots,validationFolderPath,bandFilePath,\n",
    "        n_classes,\n",
    "        n_features,\n",
    "        batch_size=batch_size,\n",
    "        rotation_range=0,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,bands=bands)\n",
    "\n",
    "#Fit the model!\n",
    "results = model.fit(train_sequence_generator, \n",
    "                    validation_data=validation_sequence_generator,validation_steps=5, \n",
    "                    epochs=5,steps_per_epoch=100,\n",
    "                    callbacks=[lr_schedule,earlystopper, checkpointer,tensorboard],\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "model.save('models/{}'.format(modelName+str(runNum+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Tensorboard\n",
    "#--logdir must be hard coded to match modelName\n",
    "log_dir_short = 'reports/tensorboard/{}'.format(modelName)\n",
    "%reload_ext tensorboard \n",
    "%tensorboard --logdir reports/tensorboard/unet\n",
    "\n",
    "\n",
    "#http://localhost:6010/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot some results!\n",
    "\n",
    "#Normalize band data\n",
    "def NormalizeData(data):\n",
    "    return data/0.15\n",
    "    #return (data + 0.2)/(0.3-0.2)\n",
    "    #return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "    \n",
    "classnames = ['No\\nloss','Hard\\ncommodities', 'Forest\\nproducts', 'Other\\ndisturbances',\n",
    "                'Soft\\ncommodities', 'Urbanization', 'Fires','Hansen\\nmistake']\n",
    "classcolors = ['#ffffff','#FCABAB','#93D896','#C5E4FC','#FBFD38','#BABABA','#FC3B26','#3540c8']\n",
    "\n",
    "#Load model\n",
    "model = keras.models.load_model('models/{}'.format(modelName+str(runNum+1)), custom_objects = {\"loss\":weighted_categorical_crossentropy(class_weights),\"iou_coef\": iou_coef, \"weighted_categorical_crossentropy\": weighted_categorical_crossentropy(class_weights)})\n",
    "\n",
    "maskToTCL = False\n",
    "\n",
    "##If you want to pick out a select number of plots\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "ids = np.random.choice(len(validationPlots), 30, replace=False)\n",
    "\n",
    "# #Otherwise load all validation plots\n",
    "# ids = np.arange(len(validationPlots))\n",
    "\n",
    "for idy in ids:\n",
    "    validationID = validationPlots[idy]\n",
    "    validationXRaw, label = read_image(validationID, labelFilePath, bandFilePath,bands=bands)\n",
    "    validationX = np.zeros((1, image_size, image_size, n_features))\n",
    "    validationX[0,:,:,:] = validationXRaw\n",
    "    \n",
    "    label = label[0]\n",
    "    ynew = model.predict(tf.convert_to_tensor(validationX, np.float32))\n",
    "    ynew = ynew[0]\n",
    "    \n",
    "\n",
    "    #Code block to filter to only loss\n",
    "    if maskToTCL == True:\n",
    "        ynew[:,:,0] = 0\n",
    "        ynew = np.argmax(ynew,axis=-1)\n",
    "        ynew = np.where(label==0, 0, ynew)\n",
    "        \n",
    "    #Otherwise just show prediction\n",
    "    else:\n",
    "        ynew = np.argmax(ynew, axis=-1)\n",
    "\n",
    "    #Get colormap\n",
    "    cmap = colors.ListedColormap(classcolors)\n",
    "    bounds=[-0.5,0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5]\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    fig1, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3,figsize=(12,6)) # two axes on figure\n",
    "    \n",
    "    #Load satellite data\n",
    "    X = np.zeros((64,64,3))\n",
    "    X[:,:,0] = validationXRaw[:,:,1]\n",
    "    X[:,:,1] = validationXRaw[:,:,2]\n",
    "    X[:,:,2] = validationXRaw[:,:,3]\n",
    "    X = NormalizeData(X)\n",
    "\n",
    "    #Plot\n",
    "    ax1.imshow(X, interpolation='none', aspect='auto')#vmin=0, vmax=num_classes,cmap='tab10')\n",
    "    ax1.set_title('Satellite for tile {} in {}'.format(validationID[0],validationID[1]))\n",
    "    ax1.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    ax2.imshow(label,cmap=cmap, norm=norm)#,vmin=0, vmax=num_classes,cmap='tab10')\n",
    "    ax2.set_title('Label for tile {} in {}'.format(validationID[0],validationID[1]))\n",
    "    ax2.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    ax3.imshow(ynew,cmap=cmap, norm=norm)#vmin=0, vmax=num_classes,cmap='tab10')\n",
    "    ax3.set_title('Prediction for tile {} in {}'.format(validationID[0],validationID[1]))\n",
    "    ax3.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    cbar = plt.colorbar(matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap), ax=[ax1,ax2,ax3],orientation='horizontal')\n",
    "    cbar.set_ticks([0,1,2,3,4,5,6,7])\n",
    "    cbar.set_ticklabels(classnames)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    #Save figure\n",
    "    #fig1.savefig('../viz/{}.png'.format(validationID), dpi=800)\n",
    "    \n",
    "#     #Get statistics of image\n",
    "#     labelValues, labelCounts = np.unique(label, return_counts=True)\n",
    "#     predValues, predCounts = np.unique(ynew, return_counts=True)\n",
    "#     print('Counts for L: ',dict(zip(labelValues, labelCounts)))\n",
    "#     print('Counts for P: ',dict(zip(predValues, predCounts)))\n",
    "#     print('Accuracy :',accuracy_score(label.flatten(), ynew.flatten()))\n",
    "#     matrix = confusion_matrix(label.flatten(), ynew.flatten())\n",
    "#     print('Accuracy by class: ',matrix.diagonal()/matrix.sum(axis=1))\n",
    "#     print('Confusion matrix for label {}: '.format(idy))\n",
    "#     print(classification_report(label.flatten(), ynew.flatten()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
