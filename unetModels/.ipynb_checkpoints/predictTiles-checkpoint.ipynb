{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0345ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@pallawi.ds/semantic-segmentation-with-u-net-train-and-test-on-your-custom-data-in-keras-39e4f972ec89\n",
    "#Keras loss functions\n",
    "#https://github.com/maxvfischer/keras-image-segmentation-loss-functions\n",
    "#https://github.com/maxvfischer/keras-image-segmentation-loss-functions/blob/master/losses/multiclass_losses.py#L107\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "utilsPath = os.path.join(Path(os.getcwd()).parent.absolute(),'utils')\n",
    "if utilsPath not in sys.path:\n",
    "    sys.path.append(utilsPath)\n",
    "#print(sys.path)\n",
    "from getTiles import image_gen\n",
    "from getTiles import read_image\n",
    "from lossFunctions import iou_coef, DiceLoss, weighted_categorical_crossentropy\n",
    "import random\n",
    "import glob\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import rasterio\n",
    "#import tensorflow.keras.backend as K\n",
    "\n",
    "from typing import Callable, Union\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, multilabel_confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from rasterio.plot import show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3bd2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484 209\n"
     ]
    }
   ],
   "source": [
    "#Define training data and test data\n",
    "\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "\n",
    "num_classes = 8\n",
    "\n",
    "labelFilePath = '../inputs/labeledTilesValidYears/plot_{}_{}.tif'\n",
    "bandFilePath = '../inputs/landsatTilesMultiYear/Landsat7_{}_{}.tif'\n",
    "\n",
    "fileNames = glob.glob('../inputs/labeledTilesValidYears/*.tif')\n",
    "fileNames.sort()\n",
    "\n",
    "plotIDYears = [[int(x.split('_')[1]),int(x.split('_')[2].split('.')[0])] for x in fileNames]\n",
    "\n",
    "plotIDS = np.unique([plotIDYears[i][0] for i in np.arange(len(plotIDYears))])\n",
    "np.random.shuffle(plotIDS)\n",
    "\n",
    "\n",
    "#Split into training and validation\n",
    "trainingPlotIDs = plotIDS[:int(len(plotIDS)*0.7)]\n",
    "validationPlotIDs = plotIDS[int(len(plotIDS)*0.7):]\n",
    "\n",
    "trainingPlots = [x for x in plotIDYears if x[0] in trainingPlotIDs]\n",
    "validationPlots = [x for x in plotIDYears if x[0] in validationPlotIDs]\n",
    "print(len(trainingPlots), len(validationPlots))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d936614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "n_classes=8\n",
    "n_features = 4\n",
    "image_size = 64\n",
    "batch_size=64\n",
    "bands = (1,5,6,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796fbf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 09:50:34.456413: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "\n",
    "#Build U-Net model\n",
    "inputs = Input((image_size, image_size, n_features))\n",
    "\n",
    "w_decay = 0.0005\n",
    "s = Lambda(lambda x: x) (inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',kernel_regularizer=l2(w_decay)) (c9)\n",
    "\n",
    "outputs = Conv2D(n_classes, (1, 1), padding=\"same\", activation=\"softmax\") (c9)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa24d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model name to save\n",
    "modelName = 'unet2'\n",
    "\n",
    "#Define if we want to reinialize a new model\n",
    "newModel = False\n",
    "\n",
    "\n",
    "# Define weights for classes!\n",
    "classnames = ['No Loss','Hard commodities', 'Forest products', 'Other disturbances',\n",
    "                'Soft commodities', 'Settlements/infrastructure', 'Fires','Hansen Mistake']\n",
    "class_weights = np.array([2, 80, 60, 100,\n",
    "                          100, 90, 100,100]).astype(float)\n",
    "\n",
    "\n",
    "model = keras.models.load_model('models/{}'.format(modelName), custom_objects = {\"loss\":weighted_categorical_crossentropy(class_weights),\"iou_coef\": iou_coef, \"weighted_categorical_crossentropy\": weighted_categorical_crossentropy(class_weights)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "classnames = ['No\\nloss','Hard\\ncommodities', 'Forest\\nproducts', 'Other\\ndisturbances',\n",
    "                'Soft\\ncommodities', 'Settlements/\\ninfrastructure', 'Fires','Hansen\\nmistake']\n",
    "classcolors = ['#ffffff','#FCABAB','#93D896','#C5E4FC','#FBFD38','#BABABA','#FC3B26','#3540c8']\n",
    "\n",
    "\n",
    "modelPath = 'models/{}'.format(modelName+'2')\n",
    "# #Load model\n",
    "model = keras.models.load_model(modelPath, custom_objects = {\"loss\":weighted_categorical_crossentropy(class_weights),\"iou_coef\": iou_coef, \"weighted_categorical_crossentropy\": weighted_categorical_crossentropy(class_weights)})\n",
    "\n",
    "\n",
    "predictionFilePath = '../outputs/{}/plot_{}_{}.tif'\n",
    "\n",
    "\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "ids = np.arange(len(validationPlots))#np.random.randint(0, high=len(validationPlots), size=len(validationPlots))#[1,2,3,5,7,9,10,200,300,200,40,20,150]\n",
    "\n",
    "\n",
    "for idy in ids:\n",
    "    validationID = validationPlots[idy]\n",
    "    validationXRaw, label = read_image(validationID, labelFilePath, bandFilePath,bands=bands)\n",
    "    validationX = np.zeros((1, image_size, image_size, n_features))\n",
    "    validationX[0,:,:,:] = validationXRaw\n",
    "    \n",
    "    ynew = model.predict(validationX)\n",
    "    ynew = ynew[0]\n",
    "    label = label[0]\n",
    "    #ynew = np.argmax(ynew, axis=-1)\n",
    "\n",
    "#     ##Code block to filter to only loss\n",
    "    ynew[:,:,0] = 0\n",
    "    ynew = np.argmax(ynew,axis=-1)\n",
    "    ynew = np.where(label==0, 0, ynew) \n",
    "    \n",
    "    \n",
    "    \n",
    "    labelsrc = rasterio.open(labelFilePath.format(validationID[0],validationID[1]))\n",
    "    profile = labelsrc.profile\n",
    "\n",
    "\n",
    "    with rasterio.open(predictionFilePath.format(modelName+'2',validationID[0],validationID[1])\n",
    "                       , 'w', **profile) as dst:\n",
    "        dst.write(array.astype(rasterio.uint8), 1)\n",
    "    \n",
    "    \n",
    "#     cmap = colors.ListedColormap(classcolors)\n",
    "#     bounds=[-0.5,0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5]\n",
    "#     norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "#     fig1, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3,figsize=(12,6)) # two axes on figure\n",
    "    \n",
    "#     X = np.zeros((64,64,3))\n",
    "#     X[:,:,0] = validationXRaw[:,:,1]\n",
    "#     X[:,:,1] = validationXRaw[:,:,2]\n",
    "#     X[:,:,2] = validationXRaw[:,:,3]\n",
    "#     X = NormalizeData(X)\n",
    "\n",
    "#     ax1.imshow(X, interpolation='none', aspect='auto')#vmin=0, vmax=num_classes,cmap='tab10')\n",
    "#     ax1.set_title('Satellite for tile {} in {}'.format(validationID[0],validationID[1]))\n",
    "#     ax1.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    \n",
    "#     ax2.imshow(label,cmap=cmap, norm=norm)#,vmin=0, vmax=num_classes,cmap='tab10')\n",
    "#     ax2.set_title('Label for tile {} in {}'.format(validationID[0],validationID[1]))\n",
    "#     ax3.imshow(ynew,cmap=cmap, norm=norm)#vmin=0, vmax=num_classes,cmap='tab10')\n",
    "#     ax3.set_title('Prediction for tile {} in {}'.format(validationID[0],validationID[1]))\n",
    "\n",
    "#     cbar = plt.colorbar(matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap), ax=[ax1,ax2,ax3],orientation='horizontal')\n",
    "#     cbar.set_ticks([0,1,2,3,4,5,6,7])\n",
    "\n",
    "#     cbar.set_ticklabels(classnames)\n",
    "\n",
    "    \n",
    "#     plt.show()\n",
    "    \n",
    "#     fig1.savefig('/Users/kristine/Desktop/Viz/{}.png'.format(idy), dpi=800)\n",
    "    \n",
    "    \n",
    "#     labelValues, labelCounts = np.unique(label, return_counts=True)\n",
    "#     predValues, predCounts = np.unique(ynew, return_counts=True)\n",
    "#     print('Counts for L: ',dict(zip(labelValues, labelCounts)))\n",
    "#     print('Counts for P: ',dict(zip(predValues, predCounts)))\n",
    "#     print('Accuracy :',accuracy_score(label.flatten(), ynew.flatten()))\n",
    "#     matrix = confusion_matrix(label.flatten(), ynew.flatten())\n",
    "#     print('Accuracy by class: ',matrix.diagonal()/matrix.sum(axis=1))\n",
    "#     #print('Confusion matrix for label {}: '.format(idy))\n",
    "#     #print(classification_report(label.flatten(), ynew.flatten()))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
