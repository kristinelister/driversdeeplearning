{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "#Import utility functions\n",
    "utilsPath = os.path.join(Path(os.getcwd()).parent.absolute(),'utils')\n",
    "if utilsPath not in sys.path:\n",
    "    sys.path.append(utilsPath)\n",
    "\n",
    "from modelFunctions import iou_coef, DiceLoss, weighted_categorical_crossentropy, prepUnetModel, compileUnetModel\n",
    "from getTiles import image_gen\n",
    "from getTiles import read_image\n",
    "\n",
    "#Import other modules\n",
    "import random\n",
    "import glob\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import rasterio\n",
    "\n",
    "from typing import Callable, Union\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, multilabel_confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from rasterio.plot import show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training tiles:  1248  Num validation tiles:  511\n",
      "First 5 training tiles:  [[103, 2001], [103, 2002], [103, 2003], [103, 2004], [103, 2005]]  First 5 validation tiles:  [[107, 2001], [107, 2002], [107, 2003], [107, 2004], [107, 2006]]\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "\n",
    "#Define seed\n",
    "seed = 30\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "\n",
    "#Define file path for label and bands\n",
    "trainingFolderPath = '../inputs/trainingPlots'\n",
    "validationFolderPath = '../inputs/validationPlots'\n",
    "bandFilePath = '../inputs/landsatTilesPostYear'\n",
    "labelFileFormat = 'plot_{}_{}.tif'\n",
    "labelFileFormat = 'Landsat7_{}_{}.tif'\n",
    "\n",
    "\n",
    "#Get list of [[plodID, treeCoverLossYear]] for training set and validation set\n",
    "trainingFileNames = glob.glob(os.path.join(trainingFolderPath,'*.tif'))\n",
    "trainingFileNames.sort()\n",
    "trainingPlots = [[int(x.split('_')[1]),int(x.split('_')[2].split('.')[0])] for x in trainingFileNames]\n",
    "\n",
    "validationFileNames = glob.glob(os.path.join(validationFolderPath,'*.tif'))\n",
    "validationFileNames.sort()\n",
    "validationPlots = [[int(x.split('_')[1]),int(x.split('_')[2].split('.')[0])] for x in validationFileNames]\n",
    "\n",
    "print('Num training tiles: ',len(trainingPlots), ' Num validation tiles: ',len(validationPlots))\n",
    "print('First 5 training tiles: ',trainingPlots[:5], ' First 5 validation tiles: ',validationPlots[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "n_classes=8\n",
    "n_features = 4\n",
    "image_size = 64\n",
    "batch_size=64\n",
    "bands = 'all'  #Format for listing bands: (1,5,6,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model name to save\n",
    "modelName = 'unet'\n",
    "runNum = 0\n",
    "\n",
    "\n",
    "#Define if we want to reinialize a new model\n",
    "newModel = True\n",
    "\n",
    "\n",
    "# Define weights for classes!\n",
    "classnames = ['No Loss','Hard commodities', 'Forest products', 'Other disturbances',\n",
    "                'Soft commodities', 'Settlements/infrastructure', 'Fires','Hansen Mistake']\n",
    "class_weights = np.array([1, 10, 10, 30,\n",
    "                          30, 30, 30,30]).astype(float)\n",
    "\n",
    "\n",
    "#Create new model\n",
    "if newModel==True:\n",
    "    model = compileUnetModel(n_classes, image_size, n_features, class_weights, learning_rate=0.001, w_decay=0.0005)\n",
    "\n",
    "# #Load model\n",
    "else:\n",
    "    model = keras.models.load_model('models/{}'.format(modelName+str(runNum)), custom_objects = {\"loss\":weighted_categorical_crossentropy(class_weights),\"iou_coef\": iou_coef, \"weighted_categorical_crossentropy\": weighted_categorical_crossentropy(class_weights)})\n",
    "\n",
    "##print to see model structure\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  9/100 [=>............................] - ETA: 2:00 - loss: 4.5871 - iou_coef: 0.9235"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ls/m3fnvjqj1qs_hsp9k3s_q1h00000gp/T/ipykernel_57247/2906447310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#Fit the model!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m results = model.fit(train_sequence_generator, \n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_sequence_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#load seed\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "\n",
    "\n",
    "#Scheduler for decreating learning rate as epochs go on\n",
    "epochCutoff = 5\n",
    "def scheduler(epoch):\n",
    "    if epoch < epochCutoff:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.001 * tf.math.exp(0.1 * (epochCutoff - epoch))\n",
    "\n",
    "#Callbacks for training\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-{}-1.h5'.format(modelName), verbose=1, save_best_only=True)\n",
    "log_dir = 'reports/tensorboard/{}/'.format(modelName) + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch'\n",
    ")\n",
    "\n",
    "#Define generator for training and validation data\n",
    "train_sequence_generator = image_gen(trainingPlots,trainingFolderPath,bandFilePath,\n",
    "        n_classes,\n",
    "        n_features,\n",
    "        batch_size,\n",
    "        rotation_range=90,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,bands=bands)\n",
    "\n",
    "\n",
    "validation_sequence_generator = image_gen(validationPlots,validationFolderPath,bandFilePath,\n",
    "        n_classes,\n",
    "        n_features,\n",
    "        batch_size=batch_size,\n",
    "        rotation_range=0,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,bands=bands)\n",
    "\n",
    "#Fit the model!\n",
    "results = model.fit(train_sequence_generator, \n",
    "                    validation_data=validation_sequence_generator,validation_steps=5, \n",
    "                    epochs=5,steps_per_epoch=100,\n",
    "                    callbacks=[lr_schedule,earlystopper, checkpointer,tensorboard],\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "model.save('models/{}'.format(modelName+str(runNum+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Tensorboard\n",
    "#--logdir must be hard coded to match modelName\n",
    "log_dir_short = 'reports/tensorboard/{}'.format(modelName)\n",
    "%reload_ext tensorboard \n",
    "%tensorboard --logdir reports/tensorboard/unet\n",
    "\n",
    "\n",
    "#http://localhost:6010/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot some results!\n",
    "\n",
    "#Normalize band data\n",
    "def NormalizeData(data):\n",
    "    return data/0.15\n",
    "    #return (data + 0.2)/(0.3-0.2)\n",
    "    #return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "    \n",
    "classnames = ['No\\nloss','Hard\\ncommodities', 'Forest\\nproducts', 'Other\\ndisturbances',\n",
    "                'Soft\\ncommodities', 'Urbanization', 'Fires','Hansen\\nmistake']\n",
    "classcolors = ['#ffffff','#FCABAB','#93D896','#C5E4FC','#FBFD38','#BABABA','#FC3B26','#3540c8']\n",
    "\n",
    "#Load model\n",
    "model = keras.models.load_model('models/{}'.format(modelName+str(runNum+1)), custom_objects = {\"loss\":weighted_categorical_crossentropy(class_weights),\"iou_coef\": iou_coef, \"weighted_categorical_crossentropy\": weighted_categorical_crossentropy(class_weights)})\n",
    "\n",
    "maskToTCL = False\n",
    "\n",
    "##If you want to pick out a select number of plots\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "ids = np.random.choice(len(validationPlots), 30, replace=False)\n",
    "\n",
    "# #Otherwise load all validation plots\n",
    "# ids = np.arange(len(validationPlots))\n",
    "\n",
    "for idy in ids:\n",
    "    validationID = validationPlots[idy]\n",
    "    validationXRaw, label = read_image(validationID, labelFilePath, bandFilePath,bands=bands)\n",
    "    validationX = np.zeros((1, image_size, image_size, n_features))\n",
    "    validationX[0,:,:,:] = validationXRaw\n",
    "    \n",
    "    label = label[0]\n",
    "    ynew = model.predict(tf.convert_to_tensor(validationX, np.float32))\n",
    "    ynew = ynew[0]\n",
    "    \n",
    "\n",
    "    #Code block to filter to only loss\n",
    "    if maskToTCL == True:\n",
    "        ynew[:,:,0] = 0\n",
    "        ynew = np.argmax(ynew,axis=-1)\n",
    "        ynew = np.where(label==0, 0, ynew)\n",
    "        \n",
    "    #Otherwise just show prediction\n",
    "    else:\n",
    "        ynew = np.argmax(ynew, axis=-1)\n",
    "\n",
    "    #Get colormap\n",
    "    cmap = colors.ListedColormap(classcolors)\n",
    "    bounds=[-0.5,0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5]\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    fig1, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3,figsize=(12,6)) # two axes on figure\n",
    "    \n",
    "    #Load satellite data\n",
    "    X = np.zeros((64,64,3))\n",
    "    X[:,:,0] = validationXRaw[:,:,1]\n",
    "    X[:,:,1] = validationXRaw[:,:,2]\n",
    "    X[:,:,2] = validationXRaw[:,:,3]\n",
    "    X = NormalizeData(X)\n",
    "\n",
    "    #Plot\n",
    "    ax1.imshow(X, interpolation='none', aspect='auto')#vmin=0, vmax=num_classes,cmap='tab10')\n",
    "    ax1.set_title('Satellite for tile {} in {}'.format(validationID[0],validationID[1]))\n",
    "    ax1.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    ax2.imshow(label,cmap=cmap, norm=norm)#,vmin=0, vmax=num_classes,cmap='tab10')\n",
    "    ax2.set_title('Label for tile {} in {}'.format(validationID[0],validationID[1]))\n",
    "    ax2.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    ax3.imshow(ynew,cmap=cmap, norm=norm)#vmin=0, vmax=num_classes,cmap='tab10')\n",
    "    ax3.set_title('Prediction for tile {} in {}'.format(validationID[0],validationID[1]))\n",
    "    ax3.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    cbar = plt.colorbar(matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap), ax=[ax1,ax2,ax3],orientation='horizontal')\n",
    "    cbar.set_ticks([0,1,2,3,4,5,6,7])\n",
    "    cbar.set_ticklabels(classnames)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    #Save figure\n",
    "    #fig1.savefig('../viz/{}.png'.format(validationID), dpi=800)\n",
    "    \n",
    "#     #Get statistics of image\n",
    "#     labelValues, labelCounts = np.unique(label, return_counts=True)\n",
    "#     predValues, predCounts = np.unique(ynew, return_counts=True)\n",
    "#     print('Counts for L: ',dict(zip(labelValues, labelCounts)))\n",
    "#     print('Counts for P: ',dict(zip(predValues, predCounts)))\n",
    "#     print('Accuracy :',accuracy_score(label.flatten(), ynew.flatten()))\n",
    "#     matrix = confusion_matrix(label.flatten(), ynew.flatten())\n",
    "#     print('Accuracy by class: ',matrix.diagonal()/matrix.sum(axis=1))\n",
    "#     print('Confusion matrix for label {}: '.format(idy))\n",
    "#     print(classification_report(label.flatten(), ynew.flatten()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
